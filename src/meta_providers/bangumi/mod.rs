use crate::models::{AnimeWork, BangumiResult, BangumiSubject, BangumiInfoboxItem, AiConfig};
use crate::ai::object_matcher::{SourceWork, CandidateWork, batch_process_searches};
use chrono::{DateTime, FixedOffset, NaiveDate, TimeZone};
use indicatif::{ProgressBar, ProgressStyle};

pub async fn search_bangumi_for_works(
    works: &[AnimeWork],
) -> Result<Vec<BangumiResult>, Box<dyn std::error::Error>> {
    let client = reqwest::Client::new();
    let mut results = Vec::new();

    // åˆ›å»ºè¿›åº¦æ¡
    let total_works = works.len();
    let pb = ProgressBar::new(total_works as u64);
    pb.set_style(
        ProgressStyle::with_template(
            "{spinner:.yellow} [{elapsed_precise}] [{bar:40.cyan/blue}] {pos}/{len} ({percent}%) {msg}"
        )
        .unwrap()
        .progress_chars("â–ˆâ–“â–’â–‘")
    );
    pb.enable_steady_tick(std::time::Duration::from_millis(250));
    pb.set_message("å‡†å¤‡æ‰¹é‡æœç´¢...");

    // å‡†å¤‡æ‰¹é‡æœç´¢ä»»åŠ¡
    let mut search_tasks = Vec::new();
    let mut work_indices = Vec::new();

    for (index, work) in works.iter().enumerate() {
        pb.set_message(format!(
            "å‡†å¤‡æœç´¢ä»»åŠ¡: {} ({}/{})",
            work.cleaned_title,
            index + 1,
            total_works
        ));

        // æ„å»ºæœç´¢å…³é”®è¯æ•°ç»„ï¼šåŒ…å«cleaned_titleå’Œkeywordsï¼Œå¹¶å»é‡
        let mut search_keywords: Vec<&str> = Vec::new();
        search_keywords.push(&work.cleaned_title);
        search_keywords.extend(work.keywords.iter().map(|s| s.as_str()));

        // å»é‡
        search_keywords.sort();
        search_keywords.dedup();

        // ä¸ºæ¯ä¸ªå…³é”®è¯åˆ›å»ºæœç´¢ä»»åŠ¡
        for keyword in search_keywords {
            // å…ˆæœç´¢Bangumiè·å–å€™é€‰ä½œå“
            let subjects = search_bangumi_with_keyword(&client, keyword, &work.air_date).await?;

            if !subjects.is_empty() {
                // åˆ›å»ºæºä½œå“
                let source_work = SourceWork {
                    original_title: work.original_title.clone(),
                    cleaned_title: work.cleaned_title.clone(),
                    air_date: work.air_date.map(|d| d.to_string()),
                    keywords: work.keywords.clone(),
                };

                // åˆ›å»ºå€™é€‰ä½œå“åˆ—è¡¨
                let candidate_works: Vec<CandidateWork> = subjects
                    .iter()
                    .map(|subject| CandidateWork::from(subject))
                    .collect();

                search_tasks.push((source_work, candidate_works));
                work_indices.push(index);

                // æ¯ä¸ªä½œå“åªä½¿ç”¨ç¬¬ä¸€ä¸ªæˆåŠŸçš„å…³é”®è¯
                break;
            }
        }

        // æ›´æ–°è¿›åº¦æ¡
        pb.inc(1);
    }

    pb.set_message("ä½¿ç”¨AIè¿›è¡Œæ‰¹é‡åŒ¹é…...");

    // ä½¿ç”¨æ‰¹é‡AIåŒ¹é…
    let ai_config = AiConfig::deepseek();
    let batch_size = 5; // æ¯æ‰¹æ¬¡5ä¸ªä»»åŠ¡
    let matched_ids = batch_process_searches(&search_tasks, &ai_config, batch_size).await?;

    // å¤„ç†åŒ¹é…ç»“æœ
    for (index, work) in works.iter().enumerate() {
        let mut found = false;

        // æŸ¥æ‰¾è¯¥ä½œå“çš„åŒ¹é…ç»“æœ
        for (task_index, &work_index) in work_indices.iter().enumerate() {
            if work_index == index {
                if let Some(bangumi_id) = matched_ids[task_index] {
                    // æ‰¾åˆ°åŒ¹é…ï¼Œåˆ›å»ºBangumiResult
                    // ä»å€™é€‰ä½œå“ä¸­æå–è¯¦ç»†ä¿¡æ¯
                    let search_task = &search_tasks[task_index];
                    let candidate_works = &search_task.1;

                    // æŸ¥æ‰¾åŒ¹é…çš„å€™é€‰ä½œå“
                    if let Some(matched_candidate) = candidate_works.iter().find(|c| c.bangumi_id == bangumi_id) {
                        let chinese_name = if !matched_candidate.chinese_title.is_empty() {
                            Some(matched_candidate.chinese_title.clone())
                        } else {
                            None
                        };

                        results.push(BangumiResult {
                            original_title: work.original_title.clone(),
                            cleaned_title: work.cleaned_title.clone(),
                            bangumi_id: Some(bangumi_id),
                            chinese_name,
                            aliases: matched_candidate.aliases.clone(),
                            air_date: work.air_date,
                            keywords: work.keywords.clone(),
                        });

                        found = true;
                        break;
                    }
                }
            }
        }

        if !found {
            results.push(BangumiResult {
                original_title: work.original_title.clone(),
                cleaned_title: work.cleaned_title.clone(),
                bangumi_id: None,
                chinese_name: None,
                aliases: Vec::new(),
                air_date: work.air_date,
                keywords: work.keywords.clone(),
            });
        }
    }

    // å®Œæˆè¿›åº¦æ¡
    pb.finish_with_message("Bangumiæ‰¹é‡æœç´¢å®Œæˆ");

    Ok(results)
}

pub async fn search_bangumi_with_keyword(
    client: &reqwest::Client,
    keyword: &str,
    air_date: &Option<NaiveDate>,
) -> Result<Vec<BangumiSubject>, Box<dyn std::error::Error>> {
    let url = "https://api.bgm.tv/v0/search/subjects";

    // æ„å»ºæ—¥æœŸèŒƒå›´æŸ¥è¯¢
    let date_range = build_air_date_filter(air_date);

    // æ„å»ºPOSTè¯·æ±‚ä½“
    let mut request_body = serde_json::json!({
        "keyword": keyword,
        "sort": "rank",
        "filter": {
            "type": [2]  // åªæœç´¢åŠ¨ç”»
        }
    });

    // å¦‚æœæœ‰æ—¥æœŸèŒƒå›´ï¼Œæ·»åŠ åˆ°è¿‡æ»¤å™¨ä¸­
    if let Some(ref date_filter) = date_range {
        request_body["filter"]["air_date"] = date_filter.clone();
    }

    // ç‰¹åˆ«è°ƒè¯•ï¼šæ£€æŸ¥æ˜¯å¦åœ¨æœç´¢é—®é¢˜ä½œå“
    let problem_keywords = vec![
        "ç ´ç”£å¯Œè±ª",
        "ã‚ã‚‹æ—¥ã€ãŠå§«æ§˜ã«ãªã£ã¦ã—ã¾ã£ãŸä»¶ã«ã¤ã„ã¦",
        "ç¾…å°é»’æˆ¦è¨˜",
        "MUZIK TIGER In the Forest ç¬¬2æœŸ",
    ];

    let is_problem_work = problem_keywords.iter().any(|k| keyword.contains(k));

    if is_problem_work {
        println!("\nğŸ” è°ƒè¯•ï¼šæ­£åœ¨æœç´¢é—®é¢˜ä½œå“çš„å…³é”®å­—: '{}'", keyword);
        println!("   æ—¥æœŸè¿‡æ»¤å™¨: {:?}", date_range);
        println!(
            "   Bangumi API è¯·æ±‚ä½“: {}",
            serde_json::to_string_pretty(&request_body).unwrap()
        );
    }

    let response = client
        .post(url)
        .header("User-Agent", "smart_bangumi_qb_rule_generator/0.1.0")
        .header("Content-Type", "application/json")
        .json(&request_body)
        .send()
        .await?;

    if is_problem_work {
        println!("   Bangumi API å“åº”çŠ¶æ€: {}", response.status());
    }

    if response.status().is_success() {
        let json_response: serde_json::Value = response.json().await?;

        // è°ƒè¯•è¾“å‡ºæœç´¢ç»“æœï¼ˆä»…é’ˆå¯¹é—®é¢˜ä½œå“ï¼‰
        if is_problem_work {
            if let Some(data_array) = json_response["data"].as_array() {
                println!("   æ‰¾åˆ° {} ä¸ªæœç´¢ç»“æœ", data_array.len());
                if !data_array.is_empty() {
                    println!(
                        "   ç¬¬ä¸€ä¸ªç»“æœ: {}",
                        serde_json::to_string_pretty(&data_array[0]).unwrap()
                    );
                }
            }
        }

        if let Some(data_array) = json_response["data"].as_array() {
            // è¿”å›æ‰€æœ‰æœç´¢ç»“æœï¼Œè®©æ‰¹é‡å¤„ç†æ¥å¤„ç†åŒ¹é…
            let subjects: Vec<BangumiSubject> = data_array
                .iter()
                .filter_map(|subject_data| {
                    serde_json::from_value::<BangumiSubject>(subject_data.clone()).ok()
                })
                .collect();

            if is_problem_work {
                println!("ğŸ” è°ƒè¯•ï¼šæ‰¾åˆ° {} ä¸ªæœç´¢ç»“æœ", subjects.len());
            }

            return Ok(subjects);
        }
    }

    if is_problem_work {
        println!("ğŸ” è°ƒè¯•ï¼šæœªæ‰¾åˆ°æœç´¢ç»“æœ");
    }

    Ok(Vec::new())
}

fn build_air_date_filter(air_date: &Option<NaiveDate>) -> Option<serde_json::Value> {
    // æ ¹æ®æ”¾é€æ—¶é—´æ„å»ºæ—¥æœŸèŒƒå›´è¿‡æ»¤å™¨
    if let Some(date) = air_date {
        // å°†NaiveDateè½¬æ¢ä¸ºJSTæ—¶åŒºï¼Œç¡®ä¿æ—¥æœŸèŒƒå›´æ­£ç¡®
        let jst_date = convert_to_jst_date(*date);

        // å¯¹äºå…·ä½“æ—¥æœŸï¼Œæœç´¢å‰å1ä¸ªæœˆçš„èŒƒå›´
        let start_date = jst_date - chrono::Duration::days(30);
        let end_date = jst_date + chrono::Duration::days(30);

        return Some(serde_json::json!([
            format!(">={}", start_date.format("%Y-%m-%d")),
            format!("<{}", end_date.format("%Y-%m-%d"))
        ]));
    }

    None
}

fn convert_to_jst_date(naive_date: NaiveDate) -> DateTime<FixedOffset> {
    // æ—¥æœ¬æ ‡å‡†æ—¶é—´ (JST) æ˜¯ UTC+9
    let jst_offset = FixedOffset::east_opt(9 * 3600).unwrap();
    jst_offset
        .from_local_datetime(&naive_date.and_hms_opt(0, 0, 0).unwrap())
        .unwrap()
}


pub fn extract_aliases_from_infobox(infobox: &[BangumiInfoboxItem]) -> Vec<String> {
    let mut aliases = Vec::new();

    for item in infobox {
        if item.key == "åˆ«å" || item.key == "ä¸­æ–‡å" || item.key == "è¯‘å" {
            match &item.value {
                serde_json::Value::String(s) => {
                    aliases.push(s.clone());
                }
                serde_json::Value::Array(arr) => {
                    for val in arr {
                        // Handle both string values and object values with "v" key
                        match val {
                            serde_json::Value::String(s) => {
                                aliases.push(s.clone());
                            }
                            serde_json::Value::Object(obj) => {
                                if let Some(serde_json::Value::String(s)) = obj.get("v") {
                                    aliases.push(s.clone());
                                }
                            }
                            _ => {}
                        }
                    }
                }
                _ => {}
            }
        }
    }

    aliases
}